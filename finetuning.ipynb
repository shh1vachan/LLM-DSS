{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fa9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes) (2.7.1+cu118)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes) (1.24.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (2024.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2fcde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset, Audio\n",
    "from tqdm import tqdm\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245a731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Loaded 452584 samples from manifest_silero_v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "manifest_path = \"manifest_silero_v2.jsonl\"  # <== меняем путь\n",
    "entries = []\n",
    "\n",
    "with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        item[\"audio_filepath\"] = item[\"audio_filepath\"].replace(\"\\\\\", \"/\")\n",
    "        entries.append({\n",
    "            \"audio\": item[\"audio_filepath\"],\n",
    "            \"text\": item[\"text\"]\n",
    "        })\n",
    "\n",
    "raw_dataset = Dataset.from_list(entries)\n",
    "print(f\"[✓] Loaded {len(raw_dataset)} samples from {manifest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e569841",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = raw_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a2a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-large-v3\"\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"russian\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b4c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAudioDataset(TorchDataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        return {\n",
    "            \"audio\": item[\"audio\"][\"array\"],\n",
    "            \"text\": item[\"text\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367a3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorWhisper:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, features):\n",
    "        audios = [f[\"audio\"] for f in features]\n",
    "        texts = [f[\"text\"] for f in features]\n",
    "\n",
    "        inputs = self.processor.feature_extractor(audios, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        labels = self.processor.tokenizer(texts, padding=\"longest\", return_tensors=\"pt\").input_ids\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_features\": inputs.input_features,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0873a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./whisper-finetuned\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=2000,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",             \n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    save_safetensors=False          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6b9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitsandbytes.optim import Adam8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096a3372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 13:24:44, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.699500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.747400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.581200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.548900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.459300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.202800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.194400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.102900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=2.4983707809448243, metrics={'train_runtime': 48303.0021, 'train_samples_per_second': 0.083, 'train_steps_per_second': 0.041, 'total_flos': 1.358999322624e+19, 'train_loss': 2.4983707809448243, 'epoch': 0.008838138334541213})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = MyAudioDataset(raw_dataset)\n",
    "data_collator = DataCollatorWhisper(processor)\n",
    "\n",
    "\n",
    "optimizer = Adam8bit(model.parameters(), lr=2e-5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.optimizer = optimizer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7d2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "model.save_pretrained(\"whisper-finetuned\", safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85bd2010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('whisper-finetuned\\\\tokenizer_config.json',\n",
       " 'whisper-finetuned\\\\special_tokens_map.json',\n",
       " 'whisper-finetuned\\\\vocab.json',\n",
       " 'whisper-finetuned\\\\merges.txt',\n",
       " 'whisper-finetuned\\\\normalizer.json',\n",
       " 'whisper-finetuned\\\\added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.feature_extractor.save_pretrained(\"whisper-finetuned\")\n",
    "processor.tokenizer.save_pretrained(\"whisper-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248dfa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
